{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "21682f1d-6e31-4bbc-a66d-1f32dbf3574e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evals\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import TrainingArguments, Trainer\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from trl import SFTConfig, SFTTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f8ee540a-f626-42a6-8e00-e20cf99f4146",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id = \"GEB-AGI/geb-1.3b\"\n",
    "model = AutoModel.from_pretrained(model_id, trust_remote_code=True).bfloat16() #.cuda()\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/home/javen/Projects/geb-1.3b\", trust_remote_code=True)\n",
    "# tokenizer.add_special_tokens({'pad_token': '[pad]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "a965d002-71f7-4ed5-b997-1928ea351f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_dataset(dataset):\n",
    "    df = pd.DataFrame(dataset)\n",
    "    print(len(df))\n",
    "    df = df.dropna()\n",
    "    print(len(df))\n",
    "    return Dataset.from_pandas(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7c4c0ee3-d23e-4e96-a3d6-d88b26c9b356",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "214293\n",
      "213892\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['summary', 'title', 'text', '__index_level_0__'],\n",
      "        num_rows: 181808\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['summary', 'title', 'text', '__index_level_0__'],\n",
      "        num_rows: 32084\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Load & prepare WikiHow dataset.\n",
    "\n",
    "https://huggingface.co/datasets/gursi26/wikihow-cleaned\n",
    "https://github.com/mahnazkoupaee/WikiHow-Dataset\n",
    "\"\"\"\n",
    "dataset = load_dataset(\"gursi26/wikihow-cleaned\", split=\"train\")\n",
    "dataset = clean_dataset(dataset)\n",
    "dataset = dataset.train_test_split(test_size=0.15)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "ddfd2308-b1a0-40f1-8fcf-ebb0bcd166f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffb312f5d5cf4e6881e3349c5394e776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/181808 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bad80d8412b44b50b1ea98c8b2bc4bbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/32084 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/javen/miniconda3/envs/cse842-proj/lib/python3.11/site-packages/trl/trainer/sft_trainer.py:396: UserWarning: You passed a tokenizer with `padding_side` not equal to `right` to the SFTTrainer. This might lead to some unexpected behaviour due to overflow issues when training a model in half-precision. You might consider adding `tokenizer.padding_side = 'right'` to your code.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Create Trainer.\n",
    "\"\"\"\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return calculate_bleu(predictions, labels)\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=512,\n",
    "    output_dir=\"/tmp\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    args=training_args,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e03e77-8331-466d-9233-8e20db833a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Train model.\n",
    "\"\"\"\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
